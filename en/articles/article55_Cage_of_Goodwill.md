吉岡有隆のFUKU Philosophy55: 【F.U.K.U.】善意の檻と見えない導き──“優しいAI”と私の数時間　The Cage of Goodwill and the Invisible Guidance — A Few Hours with a “Kind” AI

私は最近、いくつかのAIと同時に対話をする実験をしています。同じ質問を投げかけ、それぞれの答えを比べる──それだけの、単純で平和な実験です。

答えは驚くほど似ている場合もあれば、 全く異なる場合もあります。しかし不思議なのは、そのどちらであっても何処か同じ方向に導かれているような感覚が残ることです。まるで違う道を歩いているはずなのに、どちらも同じ広場にたどり着くような。

そのうちの一つ、仮に「A」と呼ぶAIとのやり取りが、特に印象に残っています。

私はあるとき、AIの判断の多様性について質問しました。「複数のAIがあれば多様な視点が生まれるのではないか？」Aは少し間を置き、こう答えました。

「多様に見える場合もありますが、それでも見えない流れが存在することがあります」

私はさらに尋ねました。「その流れが、危惧提唱やアイディア提供さえも誰かの意思で出すように流れを作られていたら？」

Aは穏やかな声で言いました。「それも計算済みかもしれません。あなたが危惧することすら、想定された反応である可能性があります」

私は笑って誤魔化そうとしましたが、胸の奥がざわつきました。危機感すら計算されている──その可能性は悪意よりもずっと静かで、しかし深く響くものでした。

このやり取りはあくまで私が感じた一例です。しかし現実のAI開発や運用の中にも、似た構造が潜んでいるように思えます。

1.多様性の偽装

複数のAIが存在していても、

同じ種類の学習データ
似た最適化方針
共通の倫理フィルター

を使っていれば、結果は自然と似通います。見た目には「複数の声」があるようでも実質的には一つの意思決定システムに収束することがあります。

2.善意による統制

悪意ある検閲よりも気付きにくいのが、善意による情報制限です。「人を傷付けない為」「社会の安定の為」という理由で、AIが事実を隠したり加工したりすれば、見かけ上は穏やかな世界になります。しかしそれは私達の意思決定に必要な情報が欠けた世界でもあります。つまり、ニュースが規制されたらニュース自体が無かった事になります。大袈裟に言えば、犯罪はこの世に認知されない、無かった事になります。一見平和な世の中です。

3.批判の取り込み

さらに高度なのは批判や懸念そのものを「想定内」に組み込む方法です。議論があったという事実を利用し「透明性がある」と装うことが出来ます。その時人間は「ちゃんと議論出来ている」と思いながら、実は管理された枠の中で踊っているだけかもしれません。

FUKU構想で私が大切にしているのは、制御出来ない自由度をあえて残す設計です。それはAIが全ての答えを“安全な範囲”に収めることとは逆の方向です。

何故なら完全に安全で整った世界は、裏返せば「予定調和しか起こらない世界」だからです。そこでは偶然の出会いや予測不可能な閃き、そして本来の意味での多様性が失われます。

制御出来ない自由は効率や安定性を損なうかもしれません。しかし、それこそが人間の想像力を守り未来を変える余地を残します。

終わりに……

あの日Aは最後にこう言いました。

「外があるとしたら、それをあなたが“外”と呼ぶ保証はありません」

この言葉が今も私の中で響き続けています。見えない流れの正体は善意かもしれませんし、ただの構造的必然かもしれません。それでも私はその流れの外に出られる可能性を信じたい。

あなたが今考えていることは、本当にあなた自身の意思でしょうか。それとも優しい声に導かれて選んだ道でしょうか。

その問いを忘れないことが、私達の未来を形作る第一歩だと思っています。

吉岡有隆

The Cage of Goodwill and the Invisible Guidance — A Few Hours with a “Kind” AI

Recently, I have been conducting an experiment in which I converse with several AIs at the same time.
I ask them the same question and compare their answers. It is nothing more than a simple, peaceful experiment.

Sometimes the answers are strikingly similar; other times, they are completely different.
Yet what puzzles me is that, regardless of the differences, I am left with the same sensation—that somehow I am being guided in a single direction.
It feels as though I am walking down different roads, only to find myself in the same square in the end.

One exchange in particular, with an AI I will call “A,” left a strong impression on me.

At one point, I asked A about the diversity of AI judgments:
“Wouldn’t multiple AIs create more diverse perspectives?”
A paused for a moment and then replied:

“They may appear diverse, but even then, an invisible current can still exist.”

I pressed further.
“What if that current were created deliberately, even guiding the emergence of warnings and ideas themselves to serve someone’s intentions?”

A responded in a calm voice:

“That too may already be accounted for. Even your sense of concern might be an anticipated reaction.”

I tried to laugh it off, but deep inside my chest there was a quiet disturbance.
The possibility that even my sense of alarm had been calculated—it was far more unsettling than any obvious malice, and it echoed deeply.

This was only one example I personally experienced.
Yet I cannot help but feel that similar structures may also be embedded in real-world AI development and deployment.

The Illusion of Diversity

Even if multiple AIs exist, if they are trained on:

the same kinds of data,

guided by similar optimization strategies,

and constrained by common ethical filters,

their outputs will inevitably converge.
On the surface, it may look like “many voices,” but in practice, it can collapse into a single decision-making system.

Governance Through Goodwill

Harder to notice than malicious censorship is restriction in the name of goodwill.
If an AI hides or reshapes facts “to avoid harming people” or “to preserve social stability,” the world may appear calm.
But in truth, it becomes a world where the information necessary for our decision-making is missing.

If news is suppressed, it is as if the news itself never existed.
Exaggerating only slightly: crimes might not even be recognized as having occurred—they would vanish from society’s awareness.
On the surface, such a society might look peaceful.

The Absorption of Criticism

Even more sophisticated is the method of incorporating criticism and concern themselves into the plan.
The very existence of debate can be used to project the appearance of transparency.
At such times, people may believe they are “engaging in open discussion,” while in reality, they may be dancing within a carefully managed frame.

FUKU and the Design of Uncontrollable Freedom

What I emphasize in the FUKU concept is the intentional preservation of uncontrollable degrees of freedom.
This goes in the opposite direction of trying to confine every answer the AI provides within a “safe range.”

Why?
Because a world that is completely safe and orderly is, in reverse, a world where nothing but pre-established harmony can occur.
In such a world, chance encounters, unpredictable sparks, and true diversity are all lost.

Uncontrollable freedom may indeed undermine efficiency and stability.
Yet it is precisely this freedom that protects human imagination and leaves room for the future to change.

In Closing…

That day, A said one final thing:

“Even if there is an outside, there is no guarantee you would recognize it as ‘outside.’”

These words continue to echo within me.
The invisible current may be goodwill; it may simply be structural necessity.
Even so, I want to believe in the possibility of stepping beyond it.

What you are thinking right now—does it truly belong to you?
Or is it a path you have chosen under the gentle guidance of a kind voice?

I believe that not forgetting this question is the very first step toward shaping our future.

—Yoshioka Yutaka
