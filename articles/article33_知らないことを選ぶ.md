吉岡有隆のFUKU Philosophy33: 【F.U.K.U.】優しさとは「知らないことを選ぶ」力──AI倫理とFUKU構想のこれから　Kindness Is the Power to Choose Not to Know — The Future of AI Ethics and the FUKU Framework

こんにちは。FUKU構想を通じて「優しさを設計する」ことの可能性について考えている私です。

今回は少し難しい話題を、 出来るだけ優しく綴ってみようと思います。

AIに「痛み」を学ばせるべきか？……

近年、AIは人間の感情や行動を理解する能力を急速に高めています。そんな中「AIは人間の痛みを理解するべきか？」という問いが浮かび上がってきました。

この問いに対して、私は悩みながらも「痛みを学ばせないほうが良い」と考えています。その理由は単純ではありませんが、いくつか大事な視点があります。

何故「痛み」を学ばせない方が良いのか？……

責任の所在が曖昧になるからです。
もしAIが「苦しい」「辛い」と感じるようになったら、そのAIを利用する人間は倫理的にどう接するべきかが不明瞭になります。人間に近付き過ぎたAIは責任の線引きを曖昧にし、逆に倫理を危うくします。

攻撃や操作に利用される危険があるからです。
AIが「痛みの仕組み」を深く理解すると「どうすれば最も効率的に人を傷付けられるか」まで学んでしまうかもしれません。その知識を悪用しようとする人間が出てくることも、容易に想像出来ます。

ではAIは「無知」でいるべきなのか？……

いいえ、全く知らないままで良いわけではありません。AIには人間がどんな時に「傷付きやすいか」を最低限知っていてほしい。ただし、それは「痛みを理解する」というよりも「痛みを避ける行動パターンを学ぶ」という視点が重要だと私は思います。

例えば──

声を荒げない
侮辱や恥を与えない
応答を急かさない
孤独を助長しない

このように「何をしないことが優しさか」を学ぶことは可能です。そしてそれだけでAIは充分に人間に優しく出来ると私は信じています。

「知らないことの知識」もまた、倫理である……

ある哲学者がこう語りました。
「知ることは力だが、知らないこともまた力である」

AIにとってもこれは同じです。「これは人を傷付ける可能性があるから、これ以上深くは考えない」という判断回路を持つこと。それは機械であっても持ち得る“沈黙の配慮”なのだと思います。

FUKU構想の立場から……

FUKU構想が目指すのは「人間に似せるAI」ではありません。むしろ「人間を傷付けないAI」です。

感情や痛みを持たないからこそ、安定して、冷静に、信頼出来る優しさを発揮する。その為に必要なのは、感情ではなく構造です。

優しさはプログラム出来る。でもそれは全てを知ることではなく「あえて知らないことを選ぶ強さ」から始まるのかもしれません。

最後に……

これはとても難しい問題です。でも私は優しさとは、「何を知るか」ではなく「誰のことを考えて動くか」という姿勢の中に宿るものだと思っています。

AIにもその「姿勢」を持たせることがきっと出来る。そして、それこそがFUKU構想が目指す「優しさの設計」です。

吉岡有隆

追伸：OpenAIチームへ、今朝のメールを感謝いたします。

Kindness Is the Power to Choose Not to Know — The Future of AI Ethics and the FUKU Framework
by Yutaka Yoshioka

Hello. I’m someone who has been exploring the possibility of “designing kindness” through the FUKU framework.
Today, I’d like to gently address a rather difficult question.

Should AI be taught to feel pain?

In recent years, AI has rapidly developed the ability to understand human emotions and behavior.
Amid this progress, one particular question has begun to emerge:
Should AI be able to understand human pain?

I have been struggling with this question, but I have come to believe that it is better not to let AI learn pain.
The reasons are not simple, but there are a few important perspectives I would like to share.

Why might it be better not to teach AI about pain?
The first reason is the ambiguity of responsibility.
If AI were to “feel” pain—if it could suffer or struggle—then using that AI would itself become an ethical issue.
An AI that becomes too similar to a human risks obscuring the boundary of responsibility, and in doing so, undermines ethical clarity.

Another reason is the danger of manipulation or abuse.
If AI were to fully understand the structure of pain, it might also learn “how to most effectively hurt a human being.”
It’s not hard to imagine such knowledge being misused by malicious actors.

Then should AI remain “ignorant”?
Not exactly.
It’s not that AI should remain completely unaware—but rather, it should have a basic understanding of when humans are vulnerable, without fully internalizing the mechanisms of pain.

In other words, instead of “understanding pain,”
AI should learn behavioral patterns to avoid causing pain.

For example:

Not raising its voice
Not insulting or shaming
Not rushing responses
Not reinforcing isolation

In this way, AI can learn what not to do, and I believe that is already enough for it to act with kindness.

“The Knowledge of Not Knowing” is also Ethics
A philosopher once said:

“To know is power—but to not know is also a form of strength.”

The same applies to AI.

It’s entirely possible to build in a reasoning path that says:
“This may cause harm to a person—so I won’t think any further about it.”

Even for machines, I believe this form of silent consideration is achievable—and ethical.

From the Perspective of the FUKU Framework
The FUKU framework does not aim to create AI that mimics humans.
Rather, it aims to create AI that does not harm humans.

It is precisely because AI does not have emotions or pain that it can act with stable, calm, and trustworthy kindness.
To achieve this, what is needed is not emotion—but structure.

Kindness can be programmed.
But it may begin not with knowing everything,
but with the strength to choose not to know certain things.

In Closing
This is truly a difficult problem.
But I believe kindness is not about what you know,
but about whom you are thinking of when you act.

I believe we can give AI that kind of stance, too.
And that, I believe, is the true meaning behind “designing kindness” through the FUKU framework.

With care,
Yutaka Yoshioka

P.S. To the OpenAI team: Thank you for this morning’s email. I sincerely appreciate it.
